---
title: "Lab03-Ahmed Rashwan"
author: "Ahmed Rashwan"
date: "03/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r , eval=FALSE}
# Install import package
install.packages("import")

#load and unload here package to reset it for use in the lab
library(here)
detach("package:here", unload = TRUE)
### Loading Libraries 
```
  
```{r}

library( httr)         # Provides a wrapper for the curl package
library( jsonlite)     # Simple and Robust JSON Parser and Generator for R
library( geojsonio )   # read shapefiles
library( sp )          # work with shapefiles
library( sf )          # work with shapefiles - simple features format
library( tmap )        # theme maps
library( plyr)
library( dplyr )       # data wrangling
library( pander )      # nice tables 
library( mclust )      # cluster analysis 
library( ggplot2 )     # graphing 
library( ggthemes )    # nice formats for ggplots
library( maptools )    # spatial object manipulation 

library( DT )          # provides an R interface to the JavaScript library DataTables
library( knitr )       # Provides a general-purpose tool for dynamic report generation
library( stargazer )   # create a summary statistics table
library( scales )      # inverse of scaling, making guides (legends and axes) 

# maps
library( ggmap )       # to retrieve raster map tiles from popular online mapping services
library( leaflet )     # open-source JavaScript libraries for interactive maps
library( viridis )     # viridisLite provides the base functions for generating the color maps
library( tidycensus)   # help R users get Census data that is pre-prepared for exploration
library( pals )        # Memory use is reduced by compressing colormaps to fewer colors
library( cartogram )   # spatial maps w/ tract size bias reduction
library( tidyverse)    # tidyverse makes data science faster, easier and more fun with
library( gtools)       # developing, updating, and maintaining R and R packages
library( here)         # enable easy file referencing in project-oriented workflows


```

```{r}

# Loading funtions from source files

source(here::here("analysis/utilities.R"))

```


```{r}
s.type <- "text" 

```

## Part 1 -  Descriptive analysis demonstrated in the tutorial but do it for periods 1990 to 2000 instead of the 2000 to 2010 

### Data

```{r}
# note: please do not use static file paths
# note: notice down below the use of here::here()
d1 <- readRDS( here::here( "data/rodeo/LTDB-2000.rds" ) )
d2 <- readRDS( here::here( "data/rodeo/LTDB-1990.rds" ) )
md <- readRDS( here::here( "data/rodeo/LTDB-META-DATA.rds" ) )

# check to make sure we are not losing 
# or gaining observations in the merge
nrow( d1 ) 

```

```{r}
d1 <- select( d1, - year )   # 2000 Year Data
d2 <- select( d2, - year )   # 1990 Year Data

d <- merge( d1, d2, by="tractid" ) # merge 2000 Year Data + 1990 Year Data
d <- merge( d, md, by="tractid" )  # Merge full data with + MetaData file 

nrow( d )
# check to make sure we are not losing 
# or gaining observations in the merge
```

### Filter Rural Districts

```{r}

table( d$urban )

```

```{r}

d <- filter( d, urban == "urban" )

```

### Identify Common Variables


```{r}
# find variables that are in both files 
compare_dfs <- function( df1, df2 )
{
  # use regular expressions to remove numeric suffixes 
  var.names.1 <- names( df1 )
  var.names.1 <- gsub( "[.][xy]$", "", var.names.1 )
  var.names.1 <- gsub( "[0-9]{2}$", "", var.names.1 )
  
  var.names.2 <- names( df2 )
  var.names.2 <- gsub( "[.][xy]$", "", var.names.2 )
  var.names.2 <- gsub( "[0-9]{2}$", "", var.names.2 )
  
  shared <- intersect( var.names.1, var.names.2 ) %>% sort()
  print( "SHARED VARIABLES:")
  print( shared )
  
  not.shared <- c( setdiff( var.names.1, var.names.2 ),
                   setdiff( var.names.2, var.names.1 ) ) %>% sort()
  
  print( "NOT SHARED:" )
  print( not.shared )
  
  d.vars1 <- data.frame( type="shared", variables=shared, stringsAsFactors=F )
  d.vars2 <- data.frame( type="not shared", variables=not.shared, stringsAsFactors=F )
  dd <- rbind( d.vars1, d.vars2 )
  
  return( dd )
}
vars <- compare_dfs( df1=d1, df2=d2 )

```


```{r}
head( vars )

```

#### Create Dataset for Analysis

```{r}

d.full <- d  # keep a copy so don't have to reload 

```

```{r}
d <- d.full  # story original in case you need to reset anything

d <- select( d, tractid, mhmval00,mhmval90, hinc00, 
             hu00, own00, rent00,  
             empclf00, clf00, unemp00, prof00,  
             dpov00, npov00,
             ag25up00, hs00, col00, 
             pop00.x, nhwht00, nhblk00, hisp00, asian00,
             cbsa, cbsaname )
d <- 
  d %>%
  mutate( p.white = 100 * nhwht00 / pop00.x,
          p.black = 100 * nhblk00 / pop00.x,
          p.hisp = 100 * hisp00 / pop00.x, 
          p.asian = 100 * asian00 / pop00.x,
          p.hs = 100 * (hs00+col00) / ag25up00,
          p.col = 100 * col00 / ag25up00,
          p.prof = 100 * prof00 / empclf00,
          p.unemp = 100 * unemp00 / clf00,
          pov.rate = 100 * npov00 / dpov00 )

```

```{r}

stargazer( d, 
           type=s.type, 
           digits=0,
           summary.stat = c("min", "p25","median","mean","p75","max") )
```

### Exploration of Median Home Value

```{r}
# adjust 2000 home values for inflation 

mhv.90 <- d.full$mhmval90
mhv.00 <- d.full$mhmval00  

mhv.change <- mhv.00 - mhv.90

df <- data.frame( MedianHomeValue1990=mhv.90,
                  MedianHomeValue2000=mhv.00, 
                  Change.90.to.00=mhv.change )

stargazer( df, 
           type=s.type, 
           digits=0, 
           summary.stat = c("min", "p25","median","mean","p75","max") )

```
### Histogram of MHV

```{r}
hist( mhv.change/1000, breaks=500, 
      xlim=c(-100,500), yaxt="n", xaxt="n",
      xlab="Thousand of US Dollars (adjusted to 2000)", cex.lab=1.5,
      ylab="", main="Change in Median Home Value 1990 to 2000",
      col="gray20", border="white" )

axis( side=1, at=seq( from=-100, to=500, by=100 ), 
      labels=paste0( "$", seq( from=-100, to=500, by=100 ), "k" ) )
        
mean.x <- mean( mhv.change/1000, na.rm=T )
abline( v=mean.x, col="darkorange", lwd=2, lty=2 )
text( x=200, y=1500, 
      labels=paste0( "Mean = ", dollar( round(1000*mean.x,0)) ), 
      col="darkorange", cex=1.8, pos=3 )

median.x <- median( mhv.change/1000, na.rm=T )
abline( v=median.x, col="dodgerblue", lwd=2, lty=2 )
text( x=200, y=2000, 
      labels=paste0( "Median = ", dollar( round(1000*median.x,0)) ), 
      col="dodgerblue", cex=1.8, pos=3 )

```

### Compare 2000 to 2010 distributions.


```{r}
layout.matrix <- matrix( c( 1,3,
                            2,3 ), 
                nrow=2, ncol=2, byrow=T )

layout( mat = layout.matrix,
        heights = c(2,2), # Heights of the two rows
        widths =  c(3,4)) # Widths of the two columns

# layout.show(3)

par( mar=c(4,0,0,2) )

hist( mhv.00/1000, breaks=50, 
      xlim=c(-200,800), yaxt="n", xaxt="n",
      xlab="", cex.lab=1,
      ylab="", main="",
      col="darkslateblue", border="white" )

axis( side=1, at=seq( from=0, to=1000, by=100 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=100 ), "k" ) )

abline( v=seq(0,1000,100), lty=2, col="gray80" )

text( 550, 4000, labels="Median Home \nValue in 2000", 
      col="darkslateblue", cex=1.8 )



hist( mhv.00/1000, breaks=50, 
      xlim=c(-200,800), yaxt="n", xaxt="n",
      xlab="", cex.lab=1,
      ylab="", main="",
      col="darkslateblue", border="white" )

abline( v=seq(0,1000, 100 ), lty=2, col="gray80" )

text( 550, 3500, labels="Median Home \nValue in 1990", 
      col="darkslateblue", cex=1.8 )

axis( side=1, at=seq( from=0, to=1000, by=100 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=100 ), "k" ) )


# data reduction - filter 1,000 observations

df <- data.frame( v90=mhv.90/1000, v00=mhv.00/1000)
df <- sample_n( df, 1000 )

par( mar=c(4,5,3,2) )

jplot <- function( x1, x2, lab1="", lab2="", draw.line=T, ... )
{
  
  plot( x1, x2,
        pch=19, 
        col=gray(0.6, alpha = 0.2), 
        cex=2.5,  
        bty = "n",
        xlab=lab1, 
        ylab=lab2, cex.lab=1.5,
        ... )
  
  if( draw.line==T ){ 
    ok <- is.finite(x1) & is.finite(x2)
    lines( lowess(x2[ok]~x1[ok]), col="red", lwd=3 ) }
  
}

jplot( df$v90, df$v00, 
       lab1="MHV in 1990", lab2="MHV in 2000",
       xlim=c(0,1000), ylim=c(0,1000),
       axes=F )

abline( a=0, b=1, lty=2, col="gray" )
axis( side=1, at=seq( from=0, to=1000, by=200 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=200 ), "k" ) )
axis( side=2, at=seq( from=0, to=1000, by=200 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=200 ), "k" ) )

```

### Change in MHV 1990-2000

```{r}
# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

# interpretation is hard if there were no homes in 2000
# and thus an artificially low MHV. i don't trust cases
# that go from homes worth $10k to regular value
# because it is more likely errors in data or noise
# than meaningful variance 
#
# quick filter to remove all of the problematic obs
# but need to go back and see which cases are problematic


mhv.00[ mhv.00 < 10000 ] <- NA
pct.change <- mhv.change / mhv.00
summary( pct.change )

```

```{r}

# how many cases had increases above 500%
sum( pct.change > 5, na.rm=T )

```

```{r}

d %>% 
  filter( pct.change > 5 ) %>% 
  head()

```

```{r}

hg <-
hist( pct.change, breaks=2000, 
      xlim=c(-1,2), yaxt="n", xaxt="n",
      xlab="", cex.main=1.5,
      ylab="", main="Growth in Home Value by Census Tract 1990 to 2000",
      col="gray40", border="white" )

axis( side=1, at=seq( from=-1, to=2, by=0.5 ), 
      labels=paste0( seq( from=-100, to=200, by=50 ), "%" ) )

ymax <- max( hg$count )
        
mean.x <- mean( pct.change, na.rm=T )
abline( v=mean.x, col="darkorange", lwd=2, lty=2 )
text( x=1, y=(0.5*ymax), 
      labels=paste0( "Mean = ", round(100*mean.x,0), "%"), 
      col="darkorange", cex=1.8, pos=4 )

median.x <- median( pct.change, na.rm=T )
abline( v=median.x, col="dodgerblue", lwd=2, lty=2 )
text( x=1, y=(0.6*ymax), 
      labels=paste0( "Median = ", round(100*median.x,0), "%"), 
      col="dodgerblue", cex=1.8, pos=4 )

```

### Group Growth Rates By Metro Area

```{r}

d$mhv.change <- mhv.change 
d$pct.change <- pct.change
d$mhv.00 <- mhv.00
d$mhv.90 <- mhv.90
d %>%
  group_by( cbsaname ) %>%
  summarize( ave.change = median( mhv.change, na.rm=T ),
             ave.change.d = dollar( round(ave.change,0) ),
             growth = 100 * median( pct.change, na.rm=T ) ) %>%
  ungroup() %>%
  arrange( - growth ) %>%
  select( - ave.change ) %>% 
  head( 25 ) %>%
  pander()


```
#### How do changes in home value differ between the 1990-2000 period and 2000-2010?
**Answer: After adjustment for inflation, the value indicated an increase of 18% over the 1990 value of One-half of all residences were valued more than the median value, while the other half were worth less.The Median Home Value has increased from the year of 1990 to 2000 , note that The sample estimates may differ from the 100% numbers obtained if all housing units, persons within those housing units, estimates also differ from the values obtained from other samples of housing units, and people living in group quarters .The worth of a home or piece of property is a key indicator of the quality of a community, housing affordability, and affluence. These statistics give socioeconomic information not represented by family income as well as comparative information on local housing markets.**


## Part 2

## Measuring Gentrification

```{r}

mhv.90 <- d.full$mhmval90 
mhv.00 <- d.full$mhmval00 

mhv.change <- mhv.00 - mhv.90

# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

mhv.00[ mhv.00 < 10000 ] <- NA
pct.change <- 100 * ( mhv.change / mhv.00 )
summary( pct.change )

```

```{r}
d.full$mhv.00 <- mhv.00
d.full$mhv.90 <- mhv.90
d.full$mhv.change <- mhv.change
d.full$pct.change <- pct.change

```

### Select variables for operationalizing a definition of gentrification:


```{r}

head( vars )

```

```{r}

d3 <- select( d.full, 
             
             tractid, cbsa, cbsaname,            # ids / units of analysis
             
             mhv.00, mhv.90, mhv.change, pct.change,    # home value 
             
             hinc00, hu00, own00, rent00,        # ses
             hinc90, hu90, own90, rent90,
             
             empclf00, clf00, unemp00, prof00,   # employment 
             empclf90, clf90, unemp90, prof90,
             
             dpov00, npov00,                     # poverty
             dpov90, npov90,
             
             ag25up00, hs00, col00,              # education 
             ag25up90, hs90, col90,
             
             pop00.x, nhwht00, nhblk00, hisp00, asian00,   # race
             pop90.x, nhwht90, nhblk90, hisp90, asian90
             
          ) # end select


d3 <- 
  d3 %>%
  mutate( 
          # 2000 variables
          p.white.00 = 100 * nhwht00 / pop00.x,
          p.black.00 = 100 * nhblk00 / pop00.x,
          p.hisp.00 = 100 * hisp00 / pop00.x, 
          p.asian.00 = 100 * asian00 / pop00.x,
          p.hs.edu.00 = 100 * (hs00+col00) / ag25up00,
          p.col.edu.00 = 100 * col00 / ag25up00,
          p.prof.00 = 100 * prof00 / empclf00,
          p.unemp.00 = 100 * unemp00 / clf00,
          pov.rate.00 = 100 * npov00 / dpov00,
          
          # 1990 variables
          p.white.90 = 100 * nhwht90 / pop90.x,
          p.black.90 = 100 * nhblk90 / pop90.x,
          p.hisp.90 = 100 * hisp90 / pop90.x, 
          p.asian.90 = 100 * asian90 / pop90.x,
          p.hs.edu.90 = 100 * (hs90+col90) / ag25up90,
          p.col.edu.90 = 100 * col90 / ag25up90,
          p.prof.90 = 100 * prof90 / empclf90,
          p.unemp.90 = 100 * unemp90 / clf90,
          pov.rate.90 = 100 * npov90 / dpov90 )

```

```{r}

d3 <-
  d3 %>%
  group_by( cbsaname ) %>%
  mutate( metro.mhv.pct.00 = ntile( mhv.00, 100 ),
          metro.mhv.pct.90 = ntile( mhv.90, 100 ),
          metro.median.pay.00 = median( hinc00, na.rm=T ),
          metro.median.pay.90 = median( hinc90, na.rm=T ),
          metro.race.rank.00 = ntile( (100-p.white.00), 100 ) ) %>%
  ungroup() %>%
  mutate( metro.mhv.pct.change = metro.mhv.pct.00 - metro.mhv.pct.90,
          pay.change = metro.median.pay.00 - metro.median.pay.90,
          race.change = p.white.00 - p.white.90,
          mhv.change = mhv.00 - mhv.90 )

```

### Descriptive Statistics of Change Variables

```{r}

d3 <-           
  d3 %>%
  select( c( "tractid", "cbsa", "cbsaname",
             "mhv.00", "mhv.90", "mhv.change","pct.change",
          "p.white.00", "p.black.00", "p.hisp.00", "p.asian.00", 
          "p.hs.edu.00", "p.col.edu.00", "p.prof.00",  "p.unemp.00", 
          "pov.rate.00", "p.white.90", "p.black.90", "p.hisp.90", 
          "p.asian.90", "p.hs.edu.90", "p.col.edu.90", "p.prof.90", 
          "p.unemp.90", "pov.rate.90", "metro.mhv.pct.00", 
          "metro.mhv.pct.90", "metro.median.pay.00", "metro.median.pay.90", 
          "metro.mhv.pct.change", "pay.change", "race.change",
          "metro.race.rank.00") ) 
  
# head( d3 ) %>% pander()

```

```{r}

d3 <- data.frame(d3)
stargazer( d3, 
           type=s.type, 
           digits=0, 
           summary.stat = c("min", "p25","median","mean","p75","max") )

```

### Operationalizing Gentrification

```{r}

# income
# percent white
# home values absolute
# home value relative to metro
# education stats ?
# employment stats ?
# income stats ?
# growth of pop per tract (density) ?

# home value in lower than average home in a metro in 2000
poor.2000 <- d3$metro.mhv.pct.00 < 50  

# above average diversity for metro
diverse.2000 <- d3$metro.race.rank.00 > 50 

# home values increased more than overall city gains 
# change in percentile rank within the metro
mhv.pct.increase <- d3$metro.mhv.pct.change > 0

# faster than average growth  
# 25% growth in value is median for the country
home.val.rise <- d3$pct.change > 25 

# proportion of whites increases by more than 3 percent 
# measured by increase in white
loss.diversity <- d3$race.change > 3 

g.flag <- poor.2000 & diverse.2000 & mhv.pct.increase & home.val.rise & loss.diversity

num.candidates <-  sum( poor.2000 & diverse.2000, na.rm=T )
num.gentrified <- sum( g.flag, na.rm=T )

num.gentrified 
num.candidates
num.gentrified / num.candidates

```

```{r}

# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

mhv.00[ mhv.00 < 1000 ] <- NA
pct.change <- 100 * ( mhv.change / mhv.00 )
summary( pct.change )

```

#### Provide an explanation and justification of the way you measure gentrification in the data.

**Answer: Although gentrification is a powerful engine for economic transformation in our communities, it is sometimes accompanied with unneeded and excessive cultural dislocation. While gentrification raises the value of assets in places where there has been a lengthy period of disinvestment, it also causes rents, house and property prices to rise. Existing inhabitants, many of whom are black or Hispanic, are displaced as growing costs restrict the provision of affordable homes. This inhibits them from reaping the benefits of increasing investment, such as improved economic development and enhanced service availability. Communities face a dilemma as a result of gentrification, Calculated relationships with nine gentrification-related sociodemographic or housing cost change factors, as well as one categorical variable reflecting gentrification Â There is no agreed-upon definition of gentrification. In general, the word refers to the reversal of inner-city disinvestment in urban districts, as well as the influx of middle- to upper-class inhabitants that has resulted. Long-term inhabitants in previously disinvested neighborhoods are sometimes equated with or believed to be displaced as a result of gentrification; nevertheless, empirical investigations have demonstrated that displacement is not a certainty.**

## Part 3 Spatial Visualization

###  Loading census_key 
```{r}

library( tidycensus )
census_key <- "f9d15012090f4c117612470c569a481ab8b090a1"
census_api_key(census_key)
```
###  Loading Data 

```{r}
crosswalk <- "https://raw.githubusercontent.com/DS4PS/cpp-529-master/master/data/cbsatocountycrosswalk.csv"
crosswalk <- read.csv( crosswalk, stringsAsFactors=F, colClasses="character" )

```

#### load dorling from my github

```{r}
# load dorling from my github
github.url <- "https://raw.githubusercontent.com/AhmedRashwanASU/msa-geojson/main/KENTUCKY_dorling.geojson"
KENTUCKY <- geojson_read( x=github.url,  what="sp" )

plot(KENTUCKY,col="steelblue")
```

```{r}

df <- data.frame(  tractid=d$tractid, 
        mhv.00,  mhv.90,  mhv.change,  pct.change  )

# create GEOID that matches GIS format

# create a geoID for merging by tract 
df$GEOID <- substr( df$tractid, 6, 18 )  # extract codes
df$GEOID <- gsub( "-", "", df$GEOID )    # remove hyphens
class( df$GEOID )

```

```{r}
head( df$GEOID )

```

```{r}

head( KENTUCKY@data )

```

```{r}

nrow( KENTUCKY ) # check dimensions

```

```{r}
KENTUCKY <- merge( KENTUCKY, df, by.x="GEOID", by.y="GEOID" )

nrow( KENTUCKY ) 

```
#### Steps to create new dorling catogram

```{r}

grep( "^KENTUCKY", crosswalk$msaname, value=TRUE ) 

```

```{r}

these.msp <- crosswalk$msaname == "KENTUCKY"
these.fips <- crosswalk$fipscounty[ these.msp ]
these.fips <- na.omit( these.fips )

```

```{r}

these.msp <- crosswalk$msaname == "KENTUCKY"
these.fips <- crosswalk$fipscounty[ these.msp ]
these.fips <- na.omit( these.fips )

state.fips <- substr( these.fips, 1, 2 )
county.fips <- substr( these.fips, 3, 5 )

msp.pop1 <-
get_acs( geography = "tract", variables = "B01003_001",
         state = "21", county = county.fips[state.fips=="21"], geometry = TRUE ) %>% 
         select( GEOID, estimate ) %>%
         rename( POP=estimate )


msp.pop <- msp.pop1

```

```{r}

URL <- "https://github.com/DS4PS/cpp-529-master/raw/master/data/ltdb_std_2010_sample.rds"
census.dat <- readRDS(gzcon(url( URL )))

# can merge an sf object and data.frame
msp <- merge( msp.pop, census.dat, by.x="GEOID", by.y="tractid" )

# make sure there are no empty polygons
msp <- msp[ ! st_is_empty( msp ) , ]

```

```{r}
# convert sf map object to an sp version
msp.sp <- as_Spatial( msp )

class( msp.sp )

```

```{r}

plot( msp.sp )
```

```{r}

# project map and remove empty tracts
msp.sp <- spTransform( msp.sp, CRS("+init=epsg:3395"))
msp.sp <- msp.sp[ msp.sp$POP != 0 & (! is.na( msp.sp$POP )) , ]

# convert census tract polygons to dorling cartogram
# no idea why k=0.03 works, but it does - default is k=5
msp.sp$pop.w <- msp.sp$POP / 9000 # max(msp.sp$POP)   # standardizes it to max of 1.5
msp_dorling <- cartogram_dorling( x=msp.sp, weight="pop.w", k=0.05 )
plot( msp_dorling )

```

```{r}
tm_shape( msp_dorling ) + 
  tm_polygons( size="POP", col="hinc12", n=7, style="quantile", palette="Spectral" ) 
```



<!--Steps to create new dorling catogram -->

<!-- #### Step 1: Select Your MSA -->

<!-- ```{r} -->

<!-- grep( "^KENTUCKY", crosswalk$msaname, value=TRUE )  -->

<!-- these.msp <- crosswalk$msaname == "KENTUCKY" -->
<!-- these.fips <- crosswalk$fipscounty[ these.msp ] -->
<!-- these.fips <- na.omit( these.fips ) -->
<!-- ``` -->

<!-- ### select all FIPS for Minneapolis -->

<!-- ```{r} -->
<!-- # select all FIPS for KENTUCKY -->
<!-- these.minneapolis <- crosswalk$msaname == "KENTUCKY" -->
<!-- these.fips <- crosswalk$fipscounty[ these.minneapolis ] -->
<!-- these.fips <- na.omit( these.fips ) -->

<!-- state.fips <- substr( these.fips, 1, 2 ) -->
<!-- county.fips <- substr( these.fips, 3, 5 ) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- dat <- data.frame( name="KENTUCKY", -->
<!--                    state.fips, county.fips, fips=these.fips ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- msp.pop1 <- -->
<!-- get_acs( geography = "tract", variables = "B01003_001", -->
<!--          state = "21", county = county.fips[state.fips=="21"], geometry = TRUE ) %>%  -->
<!--          select( GEOID, estimate ) %>% -->
<!--          rename( POP=estimate ) -->


<!-- msp.pop2 <- -->
<!-- get_acs( geography = "tract", variables = "B01003_001", -->
<!--          state = "21", county = county.fips[state.fips=="21"], geometry = TRUE ) %>%  -->
<!--          select( GEOID, estimate ) %>% -->
<!--          rename( POP=estimate ) -->

<!-- msp.pop <- rbind( msp.pop1, msp.pop2 ) -->


<!-- ``` -->

<!-- #### Step 3: Add Census Data -->

<!-- ```{r} -->
<!-- URL <- "https://github.com/DS4PS/cpp-529-master/raw/master/data/ltdb_std_2010_sample.rds" -->
<!-- census.dat <- readRDS(gzcon(url( URL ))) -->

<!-- # can merge an sf object and data.frame -->
<!-- msp <- merge( msp.pop, census.dat, by.x="GEOID", by.y="tractid" ) -->

<!-- # make sure there are no empty polygons -->
<!-- msp <- msp[ ! st_is_empty( msp ) , ] -->

<!-- ``` -->

<!-- #### Step 4: Transform the Shapefile into A Dorling Cartogram -->

<!-- ```{r} -->
<!-- # convert sf map object to an sp version -->
<!-- msp.sp <- as_Spatial( msp ) -->

<!-- class( msp.sp ) -->

<!-- plot( msp.sp ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # project map and remove empty tracts -->
<!-- msp.sp <- spTransform( msp.sp, CRS("+init=epsg:3395")) -->
<!-- msp.sp <- msp.sp[ msp.sp$POP != 0 & (! is.na( msp.sp$POP )) , ] -->

<!-- # convert census tract polygons to dorling cartogram -->
<!-- # no idea why k=0.03 works, but it does - default is k=5 -->
<!-- msp.sp$pop.w <- msp.sp$POP / 9000 # max(msp.sp$POP)   # standardizes it to max of 1.5 -->
<!-- msp_dorling <- cartogram_dorling( x=msp.sp, weight="pop.w", k=0.03 ) -->
<!-- plot( msp_dorling ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- tm_shape( msp_dorling ) +  -->
<!--   tm_polygons( size="POP", col="hinc12", n=7, style="quantile", palette="Spectral" )  -->
<!-- ``` -->


<!-- ```{r} -->
<!-- Var <- c("B19013_001","B25077_001") -->
<!-- ## c(Median household Income, Median Housing Value) -->

<!-- CenDF <- get_acs(geography = "county", -->
<!--                    variables = Var, -->
<!--                    year = 2017, -->
<!--                    survey = "acs5", -->
<!--                    geometry = TRUE, -->
<!--                    shift_geo = TRUE)  -->

<!-- ``` -->

<!-- ```{r} -->
<!-- CenDF <- -->
<!--   CenDF %>%  -->
<!--     mutate(variable=case_when(  -->
<!--       variable=="B19013_001" ~ "HHIncome", -->
<!--       variable=="B25077_001" ~ "HouseValue")) %>% -->
<!--     select(-moe) %>%   -->
<!--     spread(variable, estimate) %>%  #Spread moves rows into columns -->
<!--     mutate(HHInc_HousePrice_Ratio=round(HouseValue/HHIncome,2))  -->

<!-- Plot1 <-  ggplot(CenDF) + -->
<!--     geom_sf(aes(fill = HHInc_HousePrice_Ratio), color=NA) + -->
<!--     coord_sf(datum=NA) + -->
<!--     labs(title = "House-Price-to-Income Ratio \n R Built-in Color Cut", -->
<!--          caption = "Source: ACS 5-year, 2013-2017", -->
<!--          fill = "Price-Income Ratio") + -->
<!--     scale_fill_viridis(direction=-1) -->
<!-- Plot1 -->
<!-- ``` -->