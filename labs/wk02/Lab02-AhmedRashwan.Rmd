---
title: "Lab02-AhmedRashwan"
output:
  html_document:
    theme: readable
    highlight: zenburn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, eval=FALSE}

# Install necessary packages
install.packages("here")

```
### Runing Needed Packages 
```{r }

# load necessary packages
library( tidyverse )
library( here )
library( pander )


```

### Part 1: Data Concordance
```{r}
# Reading data files from specific file paths in my desktop


# store data dictionary file path
DD_FILEPATH <- here::here("data/rodeo/Ahmeds-ltdb_data_dictionary.csv")

# import data dictionary
dd <- read.csv(DD_FILEPATH , header=T,fill=T , stringsAsFactors=F)
head(dd) %>% pander()

```

```{r}

# rename columns to lower case in both data frames 


dd <- as.data.frame( sapply( dd, tolower) )

ltdb.data <- as.data.frame( sapply( dd, tolower) )

# remove the second root column
dd <- select( dd, -root2 )

# view a subset of columns 
dd[ c(1:5,15:17), ] %>% pander()

```
### Part 2: Build a Variable Filter


### Loading funtions from utilities.R file

```{r}

# Loading funtions from source files

source(here::here("analysis/utilities.R"))

```

### Running functions 

```{r}
# Run the date function

today()

cat_filter (dd,c("age", "race")) %>% pander()

search_description(dd , "*income*") %>% pander()

time_search( dd, "1990|1980|1970") %>% pander()

```
### RDS vs CSV formats

#### new concordance version of the data dictionary was created by reading in all of the current datasets, compiling all of the current variable names, organizing them by source, copying some definitions from the current PDF of the LTDB dictionary

```{r , eval=FALSE}
# store the raw data directory
RAW_DATA_DIR <- here::here("/data/raw/")

# print a list of files in the directory
all_files <- list.files(RAW_DATA_DIR)

# store the relevant files
relevant_files <-
  # from the list, use regex to only extract the relevant files
  stringr::str_subset(string = all_files, pattern = "_(sample|fullcount).csv") %>%
  # add the static file path back to the relevant files
  purrr::map_chr(.f = ~ glue::glue(RAW_DATA_DIR, .x))


# read a file
# create code for type (full/sample)
# create code for year
# return a tidy table with var attributes

all.sets <- NULL

# notice the singular name that represents one element within the vector
for( relevant_file in relevant_files )
{
  type <- ifelse( grepl( "sample", relevant_file ), "sample", "full" )
  year <- 
    # extract the year
    stringr::str_extract(relevant_file, "_//d{4}_") %>% 
    # convert from string to numeric
    readr::parse_number()
  # read data
  dat <- read.csv( relevant_file )
  vars <- names(dat) 
  d <- data.frame( vars, year, type, stringsAsFactors=F )
  all.sets <- rbind( all.sets, d )
  
}


head( all.sets )

length( unique( all.sets$vars ) )

all.sets$year.t <- paste0( all.sets$year, ".", substr( all.sets$type, 1, 1 ) )

x <- all.sets$vars

x <- tolower(x)

x[ x == "state" ]  <- "stateXX"
x[ x == "county" ] <- "countyXX"
x[ x == "tract" ]  <- "tractXX"
x[ x == "tractid" ]  <- "tractidXX"

# remove census SF and SP table suffixes
# on handful of variable names 

x <- gsub( "[0-9]{2}sp1$", "sp1XX", x )
x <- gsub( "[0-9]{2}sp2$", "sp2XX", x )
x <- gsub( "[0-9]{2}sf3$", "sf3XX", x )
x <- gsub( "[0-9]{2}sf4$", "sf4XX", x )

root <- substr( x, 1, nchar(x)-2 ) 

all.sets$root <- root 

d <- select( all.sets, root, year.t, vars )

# convert from tidy table
# to a matrix of variables
#
# one concept per row ("root")
# columns are years + full or sample
# cells are variable names from raw files

dd <- spread( d, key=year.t, value=vars, fill="" )


# problem solve some var names 

> d[ c(51,64), ]
     root year.t     vars
51 POP70S 1970.s POP70SP2
64 POP70S 1970.s POP70SP1
> d[ c(168,221), ]
      root year.t     vars
168 pop80s 1980.s pop80sf3
221 pop80s 1980.s pop80sf4
> d[ c(293,294), ]
      root year.t     vars
293 POP90S 1990.s POP90SF3
294 POP90S 1990.s POP90SF4
> d[ c(486,489), ]
     root year.t    vars
486 tract 2010.f tractid
489 tract 2010.f tractXX


# copied variable names and definitions from the 
# current PDF of the LTDB data dictionary

# first open the data dictionary
DATA_DICTIONARY_PATH <- here::here("data/LTDB-codebook.pdf")
# store the command to open the file programtically
open_pdf_command <- glue::glue("open", " ", '"', DATA_DICTIONARY_PATH, '"')
# open the pdf
system(open_pdf_command)

# NOTE: with your cursor, go to page 2. From page 2, look for the text 
# "% white, non-Hispanic *"
# hold your cursor and highlight all the text (include check marks)
# until you see the following text on page 4
# "% female-headed families with children"
# Finally, copy the text.

# store the copied text within the variable y.
y <- readr::clipboard()  

if (length(y) == 745) {
  print("You've copied the same amount of text as the instructor. Move forward.")
} else {
  print("You have not copied the same amount of text as the instructor. YMMV.")
}

y2 <- gsub( " [*]", "", y )
y3 <- gsub( "%", "pct", y2 )
y4 <- y3[ -49 ]

def <- matrix( y4, ncol=2, byrow=T )
def <- as.data.frame( def, stringsAsFactors=F )
names( def ) <- c("definition","root")
def$root <- substr( def$root, 1, nchar(def$root)-2 ) 

head( def )

# add definitions to subset of vars

dd <- merge( dd, def, by="root", all.x=T )

new.order <- 
  c("root", "definition", 
    "1970.f", "1970.s", "1980.f", "1980.s", 
    "1990.f", "1990.s", 
    "2000.f", "2000.s", "2010.f", "2010.s" )

dd <- dd[ new.order ]

# replace NAs with blank cells in definition column 
dd$definition[ is.na( dd$definition ) ] <- ""

write.csv( dd, here::here("data/wrangling/ltdb_data_dictionary.csv"), row.names=F )
saveRDS( dd, here::here("data/wrangling/ltdb_data_dictionary.rds" ))

```







